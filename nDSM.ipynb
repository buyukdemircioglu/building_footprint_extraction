{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c6b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n",
      "Number GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from segmentation_models import Unet, get_preprocessing\n",
    "from segmentation_models.losses import bce_dice_loss\n",
    "from segmentation_models.metrics import f1_score\n",
    "\n",
    "print(\"Number GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156f663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Parameters ###\n",
    "\n",
    "MODEL = Unet\n",
    "BACKBONE = \"resnet50\"\n",
    "EPOCH = 100\n",
    "\n",
    "OPTIMIZER = \"Adam\"\n",
    "METRICS = [f1_score]\n",
    "LOSS = bce_dice_loss\n",
    "MONITOR = \"val_f1-score\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 4\n",
    "\n",
    "MODEL_NAME = f\"{MODEL.__name__}_{BACKBONE}_{EPOCH}epoch_nDSM\"\n",
    "os.makedirs(f'{MODEL_NAME}\\\\Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Generating List of True Ortophotos for training\n",
    "# trueop_train = open(\"train_tiles_trueop_manual.txt\", \"w\")\n",
    "# trueop_train.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\trueop\\\\train'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             trueop_train.write(fpath + \"\\n\")\n",
    "# trueop_train.close()\n",
    "\n",
    "# # Generating List of nDSM for training\n",
    "# ndsm_train = open(\"train_tiles_ndsm_manual.txt\", \"w\")\n",
    "# ndsm_train.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\ndsm\\\\train'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             ndsm_train.write(fpath + \"\\n\")\n",
    "# ndsm_train.close()\n",
    "    \n",
    "# # Generating List of masks for training\n",
    "# mask_train = open(\"train_tiles_mask_manual.txt\", \"w\")\n",
    "# mask_train.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\mask\\\\train'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             mask_train.write(fpath + \"\\n\")\n",
    "# mask_train.close()\n",
    "\n",
    "# # TEST ###################33\n",
    "# trueop_test = open(\"test_tiles_trueop_manual.txt\", \"w\")\n",
    "# trueop_test.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\trueop\\\\test'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             trueop_test.write(fpath + \"\\n\")\n",
    "# trueop_test.close()\n",
    "\n",
    "# # Generating List of nDSM for training\n",
    "# ndsm_test = open(\"test_tiles_ndsm_manual.txt\", \"w\")\n",
    "# ndsm_test.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\ndsm\\\\test'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             ndsm_test.write(fpath + \"\\n\")\n",
    "# ndsm_test.close()\n",
    "    \n",
    "# # Generating List of masks for training\n",
    "# mask_test = open(\"test_tiles_mask_manual.txt\", \"w\")\n",
    "# mask_test.write(\"id\\n\")\n",
    "# for path, subdirs, _ in os.walk(r'new_test_data\\\\mask\\\\test'):\n",
    "#     for dir in _:\n",
    "#         if dir.endswith(\".tif\"):\n",
    "#             fpath = os.path.join(path, dir)\n",
    "#             mask_test.write(fpath + \"\\n\")\n",
    "# mask_test.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d60e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating List of True Ortophotos for training\n",
    "trueop_train = open(\"new_train_tiles_trueop_manual.txt\", \"w\")\n",
    "trueop_train.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\trueop\\\\train'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            trueop_train.write(fpath + \"\\n\")\n",
    "trueop_train.close()\n",
    "\n",
    "# Generating List of nDSM for training\n",
    "ndsm_train = open(\"new_train_tiles_ndsm_manual.txt\", \"w\")\n",
    "ndsm_train.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\ndsm\\\\train'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            ndsm_train.write(fpath + \"\\n\")\n",
    "ndsm_train.close()\n",
    "    \n",
    "# Generating List of masks for training\n",
    "mask_train = open(\"new_train_tiles_mask_manual.txt\", \"w\")\n",
    "mask_train.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\mask\\\\train'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            mask_train.write(fpath + \"\\n\")\n",
    "mask_train.close()\n",
    "\n",
    "\n",
    "# TEST ###################33\n",
    "trueop_test = open(\"new_test_tiles_trueop_manual.txt\", \"w\")\n",
    "trueop_test.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\trueop\\\\test'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            trueop_test.write(fpath + \"\\n\")\n",
    "trueop_test.close()\n",
    "\n",
    "# Generating List of nDSM for training\n",
    "ndsm_test = open(\"new_test_tiles_ndsm_manual.txt\", \"w\")\n",
    "ndsm_test.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\ndsm\\\\test'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            ndsm_test.write(fpath + \"\\n\")\n",
    "ndsm_test.close()\n",
    "    \n",
    "# Generating List of masks for training\n",
    "mask_test = open(\"new_test_tiles_mask_manual.txt\", \"w\")\n",
    "mask_test.write(\"id\\n\")\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\mask\\\\test'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            fpath = os.path.join(path, dir)\n",
    "            mask_test.write(fpath + \"\\n\")\n",
    "mask_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce121ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_trueop = pd.read_csv(\"train_tiles_trueop_manual.txt\")\n",
    "# train_data_mask = pd.read_csv(\"train_tiles_mask_manual.txt\")\n",
    "# train_data_nDSM = pd.read_csv(\"train_tiles_nDSM_manual.txt\")\n",
    "\n",
    "# val_data_trueop = pd.read_csv(\"val_tiles_trueop_manual.txt\")\n",
    "# val_data_mask = pd.read_csv(\"val_tiles_mask_manual.txt\")\n",
    "# val_data_nDSM = pd.read_csv(\"val_tiles_nDSM_manual.txt\")\n",
    "\n",
    "# test_data_trueop = pd.read_csv(\"test_tiles_trueop_manual.txt\")\n",
    "# test_data_mask = pd.read_csv(\"test_tiles_mask_manual.txt\")\n",
    "# test_data_nDSM = pd.read_csv(\"test_tiles_nDSM_manual.txt\")\n",
    "train_data_trueop = pd.read_csv(\"new_train_tiles_trueop_manual.txt\")\n",
    "train_data_mask = pd.read_csv(\"new_train_tiles_mask_manual.txt\")\n",
    "train_data_nDSM = pd.read_csv(\"new_train_tiles_nDSM_manual.txt\")\n",
    "\n",
    "\n",
    "test_data_trueop = pd.read_csv(\"new_test_tiles_trueop_manual.txt\")\n",
    "test_data_mask = pd.read_csv(\"new_test_tiles_mask_manual.txt\")\n",
    "test_data_nDSM = pd.read_csv(\"new_test_tiles_nDSM_manual.txt\")\n",
    "\n",
    "# index = [i for i in range(train_data_trueop.shape[0])]\n",
    "# # random.shuffle(index)\n",
    "\n",
    "# train_data_trueop_reind = train_data_trueop.set_index([index]).sort_index()\n",
    "# train_data_mask_reind = train_data_mask.set_index([index]).sort_index()\n",
    "# train_data_nDSM_reind = train_data_nDSM.set_index([index]).sort_index()\n",
    "\n",
    "# val_data_size = int(train_data_trueop_reind.shape[0] * 0.2)\n",
    "# valid_ids = train_data_trueop_reind[:val_data_size]\n",
    "# train_ids = train_data_trueop_reind[val_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6857a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_indx = 0\n",
    "# for i in range(train_data_trueop.shape[0]):\n",
    "#     keep_indx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e474c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_indx = keep_indx + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d232470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# val_data_path = 'data\\\\trueop\\\\validation'\n",
    "# for i in range(val_data_trueop.shape[0]):\n",
    "#     new_tif_path = new_dirname + \"\\\\\" \"training_tile_{}.tif\".format(new_indx)\n",
    "#     new_tfw_path = new_dirname + \"\\\\\" \"training_tile_{}.tfw\".format(new_indx)\n",
    "#     old_tfw_path = val_data_path + \"\\\\\" + os.path.splitext(os.path.basename(val_data_trueop[\"id\"][i]))[0] + \".tfw\"\n",
    "#     shutil.copy(val_data_trueop[\"id\"][i], new_tif_path)\n",
    "#     shutil.copy(old_tfw_path, new_tfw_path)\n",
    "#     new_indx += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956a7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# val_mask_data_path = 'data\\\\mask\\\\validation'\n",
    "# new_dirname = 'data_new\\\\mask\\\\train'\n",
    "# for i in range(val_data_mask.shape[0]):\n",
    "#     new_tif_path = new_dirname + \"\\\\\" \"training_tile_{}.tif\".format(new_indx)\n",
    "#     new_tfw_path = new_dirname + \"\\\\\" \"training_tile_{}.tfw\".format(new_indx)\n",
    "#     old_tfw_path = val_mask_data_path + \"\\\\\" + os.path.splitext(os.path.basename(val_data_mask[\"id\"][i]))[0] + \".tfw\"\n",
    "#     shutil.copy(val_data_mask[\"id\"][i], new_tif_path)\n",
    "#     shutil.copy(old_tfw_path, new_tfw_path)\n",
    "#     new_indx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# val_ndsm_data_path = 'data\\\\ndsm\\\\validation'\n",
    "# new_dirname = 'data_new\\\\ndsm\\\\train'\n",
    "# for i in range(val_data_nDSM.shape[0]):\n",
    "#     new_tif_path = new_dirname + \"\\\\\" \"training_tile_{}.tif\".format(new_indx)\n",
    "#     new_tfw_path = new_dirname + \"\\\\\" \"training_tile_{}.tfw\".format(new_indx)\n",
    "#     old_tfw_path = val_ndsm_data_path + \"\\\\\" + os.path.splitext(os.path.basename(val_data_nDSM[\"id\"][i]))[0] + \".tfw\"\n",
    "#     shutil.copy(val_data_nDSM[\"id\"][i], new_tif_path)\n",
    "#     shutil.copy(old_tfw_path, new_tfw_path)\n",
    "#     new_indx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc14f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_list_train = []\n",
    "file_ids = open(\"cache_tiles_train.txt\", \"w\")\n",
    "for i in range(train_data_trueop.shape[0]):\n",
    "    truop_img= tifffile.imread(train_data_trueop[\"id\"][i])\n",
    "    if truop_img.max() == 0 or truop_img.shape[2] == 4:\n",
    "        file_ids.write(train_data_trueop[\"id\"][i] + \"\\n\")\n",
    "        cache_list_train.append(i)\n",
    "remove_indxs = np.array(cache_list_train)\n",
    "\n",
    "train_data_trueop.drop(remove_indxs, axis=0, inplace=True)\n",
    "train_data_mask.drop(remove_indxs, axis=0, inplace=True)\n",
    "train_data_nDSM.drop(remove_indxs, axis=0, inplace=True)\n",
    "\n",
    "train_data_trueop_reind = train_data_trueop.reset_index(drop=True)\n",
    "train_data_mask_reind = train_data_mask.reset_index(drop=True)\n",
    "train_data_nDSM_reind=train_data_nDSM.reset_index(drop=True)\n",
    "\n",
    "file_ids.close()\n",
    "\n",
    "cache_list_test = []\n",
    "file_ids = open(\"cache_tiles_test.txt\", \"w\")\n",
    "for i in range(test_data_trueop.shape[0]):\n",
    "    truop_img= tifffile.imread(test_data_trueop[\"id\"][i])\n",
    "    if truop_img.max() == 0 or truop_img.shape[2] == 4:\n",
    "        file_ids.write(test_data_trueop[\"id\"][i] + \"\\n\")\n",
    "        cache_list_test.append(i)\n",
    "remove_indxs = np.array(cache_list_test)\n",
    "\n",
    "test_data_trueop.drop(remove_indxs, axis=0, inplace=True)\n",
    "test_data_mask.drop(remove_indxs, axis=0, inplace=True)\n",
    "test_data_nDSM.drop(remove_indxs, axis=0, inplace=True)\n",
    "\n",
    "test_data_trueop_reind = test_data_trueop.reset_index(drop=True)\n",
    "test_data_mask_reind = test_data_mask.reset_index(drop=True)\n",
    "test_data_nDSM_reind=test_data_nDSM.reset_index(drop=True)\n",
    "file_ids.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2612b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "X_train = np.zeros((len(train_data_trueop), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "Y_train = np.zeros((len(train_data_trueop), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "for i in range(len(train_data_trueop)):\n",
    "    cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    truop_img= tifffile.imread(train_data_trueop[\"id\"][i])\n",
    "    mask_img = tifffile.imread(train_data_mask[\"id\"][i])\n",
    "    ndsm_img = tifffile.imread(train_data_nDSM[\"id\"][i])\n",
    "    #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "    cache[:,:, :3] = truop_img\n",
    "    cache[:,:, 3] = ndsm_img    \n",
    "    X_train[i] = cache\n",
    "    mask = mask_img[:,:,0]\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    Y_train[i] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a555b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################################################################################################\n",
    "# X_val = np.zeros((len(val_data_trueop_reind), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# Y_val= np.zeros((len(val_data_trueop_reind), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# # indx=0\n",
    "\n",
    "# for i in range(len(val_data_trueop)):\n",
    "#     cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#     truop_img= tifffile.imread(val_data_trueop_reind[\"id\"][i])\n",
    "#     mask_img = tifffile.imread(val_data_mask_reind[\"id\"][i])\n",
    "#     ndsm_img = tifffile.imread(val_data_nDSM_reind[\"id\"][i])\n",
    "#     #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "#     cache[:,:, :3] = truop_img\n",
    "#     cache[:,:, 3] = ndsm_img    \n",
    "#     X_val[i] = cache\n",
    "#     mask = mask_img[:,:,0]\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     Y_val[i] = mask\n",
    "#     # indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################\n",
    "X_test = np.zeros((len(test_data_trueop), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "Y_test= np.zeros((len(test_data_trueop), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "\n",
    "for i in range(len(test_data_trueop)):\n",
    "    cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    truop_img= tifffile.imread(test_data_trueop[\"id\"][i])\n",
    "    mask_img = tifffile.imread(test_data_mask[\"id\"][i])\n",
    "    ndsm_img = tifffile.imread(test_data_nDSM[\"id\"][i])\n",
    "    #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "    cache[:,:, :3] = truop_img\n",
    "    cache[:,:, 3] = ndsm_img    \n",
    "    X_test[i] = cache\n",
    "    mask = mask_img[:,:,0]\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    Y_test[i] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f22397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_trueop[\"id\"][i], train_data_mask[\"id\"][i], train_data_nDSM[\"id\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24182372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# indx=0\n",
    "\n",
    "# for i in train_ids.index:\n",
    "#     cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#     truop_img= tifffile.imread(train_data_trueop_reind[\"id\"][i])\n",
    "#     mask_img = tifffile.imread(train_data_mask_reind[\"id\"][i])\n",
    "#     ndsm_img = tifffile.imread(train_data_nDSM_reind[\"id\"][i])\n",
    "#     #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "#     cache[:,:, :3] = truop_img\n",
    "#     cache[:,:, 3] = ndsm_img    \n",
    "#     X_train[indx] = cache\n",
    "#     mask = mask_img[:,:,0]\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     Y_train[indx] = mask\n",
    "#     indx += 1\n",
    "\n",
    "######################################################################################################\n",
    "# X_train = np.zeros((len(train_data_trueop), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# Y_train = np.zeros((len(train_data_trueop), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# #indx=0\n",
    "\n",
    "# for i in range(len(train_data_trueop)):\n",
    "#     cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#     truop_img= tifffile.imread(train_data_trueop[\"id\"][i])\n",
    "#     mask_img = tifffile.imread(train_data_mask[\"id\"][i])\n",
    "#     ndsm_img = tifffile.imread(train_data_nDSM[\"id\"][i])\n",
    "#     #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "#     cache[:,:, :3] = truop_img\n",
    "#     cache[:,:, 3] = ndsm_img    \n",
    "#     X_train[i] = cache\n",
    "#     mask = mask_img[:,:,0]\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     Y_train[i] = mask\n",
    "#     # indx += 1\n",
    "\n",
    "######################################################################################################\n",
    "# X_val = np.zeros((len(val_data_trueop), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# Y_val= np.zeros((len(val_data_trueop), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# # indx=0\n",
    "\n",
    "# for i in range(len(val_data_trueop)):\n",
    "#     cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#     truop_img= tifffile.imread(val_data_trueop[\"id\"][i])\n",
    "#     mask_img = tifffile.imread(val_data_mask[\"id\"][i])\n",
    "#     ndsm_img = tifffile.imread(val_data_nDSM[\"id\"][i])\n",
    "#     #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "#     cache[:,:, :3] = truop_img\n",
    "#     cache[:,:, 3] = ndsm_img    \n",
    "#     X_val[i] = cache\n",
    "#     mask = mask_img[:,:,0]\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     Y_val[i] = mask\n",
    "#     # indx += 1\n",
    "\n",
    "######################################################################################################\n",
    "# X_test = np.zeros((len(test_data_trueop), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# Y_test= np.zeros((len(test_data_trueop), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "# # indx=0\n",
    "\n",
    "# for i in range(len(test_data_trueop)):\n",
    "#     cache = np.zeros((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "#     truop_img= tifffile.imread(test_data_trueop[\"id\"][i])\n",
    "#     mask_img = tifffile.imread(test_data_mask[\"id\"][i])\n",
    "#     ndsm_img = tifffile.imread(test_data_nDSM[\"id\"][i])\n",
    "#     #ndsm_img[np.where(ndsm_img==-32767)] = 0 \n",
    "#     cache[:,:, :3] = truop_img\n",
    "#     cache[:,:, 3] = ndsm_img    \n",
    "#     X_test[i] = cache\n",
    "#     mask = mask_img[:,:,0]\n",
    "#     mask = np.expand_dims(mask, axis=-1)\n",
    "#     Y_test[i] = mask\n",
    "#     # indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aea2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"X_train_manual\", X_train)\n",
    "# np.save(\"Y_train_manual\", Y_train)\n",
    "# np.save(\"X_val_manual\", X_val)\n",
    "# np.save(\"Y_val_manual\", Y_val)\n",
    "# np.save(\"X_test_manual\", X_test)\n",
    "# np.save(\"Y_test_manual\", Y_test)\n",
    "np.save(\"new_X_train_manual\", X_train)\n",
    "np.save(\"new_Y_train_manual\", Y_train)\n",
    "np.save(\"new_X_test_manual\", X_test)\n",
    "np.save(\"new_Y_test_manual\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50cc0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"new_X_train_manual.npy\")\n",
    "Y_train = np.load(\"new_Y_train_manual.npy\")\n",
    "X_test= np.load(\"new_X_test_manual.npy\")\n",
    "Y_test = np.load(\"new_Y_test_manual.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eadd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "from sklearn.model_selection import train_test_split\n",
    "# load your data\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.111, random_state=42)\n",
    "\n",
    "# preprocess input\n",
    "x_train = preprocess_input(x_train)\n",
    "x_val = preprocess_input(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0692f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_NAME}\\\\{MODEL_NAME}.h5', verbose=1, save_best_only=True, monitor=MONITOR, mode='max')\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(f'{MODEL_NAME}\\\\{MODEL_NAME}_log.csv', separator=',', append=False)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1, monitor=MONITOR, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d82beca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "286/286 [==============================] - 188s 531ms/step - loss: 0.4560 - f1-score: 0.7526 - val_loss: 0.1266 - val_f1-score: 0.9421\n",
      "\n",
      "Epoch 00001: val_f1-score improved from -inf to 0.94213, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 145s 507ms/step - loss: 0.1651 - f1-score: 0.9179 - val_loss: 0.1189 - val_f1-score: 0.9473\n",
      "\n",
      "Epoch 00002: val_f1-score improved from 0.94213 to 0.94727, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 153s 534ms/step - loss: 0.1434 - f1-score: 0.9283 - val_loss: 0.1024 - val_f1-score: 0.9520\n",
      "\n",
      "Epoch 00003: val_f1-score improved from 0.94727 to 0.95201, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 148s 516ms/step - loss: 0.1335 - f1-score: 0.9325 - val_loss: 0.0922 - val_f1-score: 0.9547\n",
      "\n",
      "Epoch 00004: val_f1-score improved from 0.95201 to 0.95470, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 152s 532ms/step - loss: 0.1312 - f1-score: 0.9355 - val_loss: 0.1129 - val_f1-score: 0.9497\n",
      "\n",
      "Epoch 00005: val_f1-score did not improve from 0.95470\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 149s 522ms/step - loss: 0.1270 - f1-score: 0.9371 - val_loss: 0.1015 - val_f1-score: 0.9530\n",
      "\n",
      "Epoch 00006: val_f1-score did not improve from 0.95470\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 137s 480ms/step - loss: 0.1407 - f1-score: 0.9294 - val_loss: 0.0884 - val_f1-score: 0.9557\n",
      "\n",
      "Epoch 00007: val_f1-score improved from 0.95470 to 0.95568, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 137s 478ms/step - loss: 0.1183 - f1-score: 0.9417 - val_loss: 0.1085 - val_f1-score: 0.9469\n",
      "\n",
      "Epoch 00008: val_f1-score did not improve from 0.95568\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 141s 495ms/step - loss: 0.1179 - f1-score: 0.9395 - val_loss: 0.0854 - val_f1-score: 0.9600\n",
      "\n",
      "Epoch 00009: val_f1-score improved from 0.95568 to 0.95996, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 143s 502ms/step - loss: 0.1118 - f1-score: 0.9446 - val_loss: 0.0973 - val_f1-score: 0.9503\n",
      "\n",
      "Epoch 00010: val_f1-score did not improve from 0.95996\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 144s 503ms/step - loss: 0.1175 - f1-score: 0.9422 - val_loss: 0.1000 - val_f1-score: 0.9525\n",
      "\n",
      "Epoch 00011: val_f1-score did not improve from 0.95996\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 140s 488ms/step - loss: 0.1079 - f1-score: 0.9469 - val_loss: 0.0903 - val_f1-score: 0.9557\n",
      "\n",
      "Epoch 00012: val_f1-score did not improve from 0.95996\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 140s 489ms/step - loss: 0.1330 - f1-score: 0.9328 - val_loss: 0.0787 - val_f1-score: 0.9605\n",
      "\n",
      "Epoch 00013: val_f1-score improved from 0.95996 to 0.96047, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 139s 487ms/step - loss: 0.1043 - f1-score: 0.9476 - val_loss: 0.0815 - val_f1-score: 0.9587\n",
      "\n",
      "Epoch 00014: val_f1-score did not improve from 0.96047\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 139s 485ms/step - loss: 0.1127 - f1-score: 0.9427 - val_loss: 0.0783 - val_f1-score: 0.9604\n",
      "\n",
      "Epoch 00015: val_f1-score did not improve from 0.96047\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 139s 486ms/step - loss: 0.1006 - f1-score: 0.9503 - val_loss: 0.0885 - val_f1-score: 0.9578\n",
      "\n",
      "Epoch 00016: val_f1-score did not improve from 0.96047\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 139s 485ms/step - loss: 0.1067 - f1-score: 0.9466 - val_loss: 0.0819 - val_f1-score: 0.9625\n",
      "\n",
      "Epoch 00017: val_f1-score improved from 0.96047 to 0.96246, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.1005 - f1-score: 0.9510 - val_loss: 0.0872 - val_f1-score: 0.9560\n",
      "\n",
      "Epoch 00018: val_f1-score did not improve from 0.96246\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.1028 - f1-score: 0.9484 - val_loss: 0.0765 - val_f1-score: 0.9636\n",
      "\n",
      "Epoch 00019: val_f1-score improved from 0.96246 to 0.96362, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 139s 486ms/step - loss: 0.0935 - f1-score: 0.9532 - val_loss: 0.0845 - val_f1-score: 0.9609\n",
      "\n",
      "Epoch 00020: val_f1-score did not improve from 0.96362\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 139s 485ms/step - loss: 0.1038 - f1-score: 0.9481 - val_loss: 0.0724 - val_f1-score: 0.9654\n",
      "\n",
      "Epoch 00021: val_f1-score improved from 0.96362 to 0.96537, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0883 - f1-score: 0.9551 - val_loss: 0.0933 - val_f1-score: 0.9551\n",
      "\n",
      "Epoch 00022: val_f1-score did not improve from 0.96537\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0962 - f1-score: 0.9527 - val_loss: 0.0796 - val_f1-score: 0.9659\n",
      "\n",
      "Epoch 00023: val_f1-score improved from 0.96537 to 0.96590, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0927 - f1-score: 0.9534 - val_loss: 0.0767 - val_f1-score: 0.9643\n",
      "\n",
      "Epoch 00024: val_f1-score did not improve from 0.96590\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0847 - f1-score: 0.9573 - val_loss: 0.0804 - val_f1-score: 0.9619\n",
      "\n",
      "Epoch 00025: val_f1-score did not improve from 0.96590\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0855 - f1-score: 0.9567 - val_loss: 0.1330 - val_f1-score: 0.9433\n",
      "\n",
      "Epoch 00026: val_f1-score did not improve from 0.96590\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0860 - f1-score: 0.9566 - val_loss: 0.0730 - val_f1-score: 0.9653\n",
      "\n",
      "Epoch 00027: val_f1-score did not improve from 0.96590\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0886 - f1-score: 0.9552 - val_loss: 0.0883 - val_f1-score: 0.9568\n",
      "\n",
      "Epoch 00028: val_f1-score did not improve from 0.96590\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0947 - f1-score: 0.9516 - val_loss: 0.0719 - val_f1-score: 0.9661\n",
      "\n",
      "Epoch 00029: val_f1-score improved from 0.96590 to 0.96606, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0799 - f1-score: 0.9598 - val_loss: 0.0760 - val_f1-score: 0.9658\n",
      "\n",
      "Epoch 00030: val_f1-score did not improve from 0.96606\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0841 - f1-score: 0.9568 - val_loss: 0.0721 - val_f1-score: 0.9644\n",
      "\n",
      "Epoch 00031: val_f1-score did not improve from 0.96606\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0785 - f1-score: 0.9604 - val_loss: 0.1535 - val_f1-score: 0.9298\n",
      "\n",
      "Epoch 00032: val_f1-score did not improve from 0.96606\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.1032 - f1-score: 0.9478 - val_loss: 0.0736 - val_f1-score: 0.9663\n",
      "\n",
      "Epoch 00033: val_f1-score improved from 0.96606 to 0.96626, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0773 - f1-score: 0.9612 - val_loss: 0.0725 - val_f1-score: 0.9667\n",
      "\n",
      "Epoch 00034: val_f1-score improved from 0.96626 to 0.96666, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0792 - f1-score: 0.9605 - val_loss: 0.0701 - val_f1-score: 0.9676\n",
      "\n",
      "Epoch 00035: val_f1-score improved from 0.96666 to 0.96759, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0772 - f1-score: 0.9599 - val_loss: 0.0973 - val_f1-score: 0.9550\n",
      "\n",
      "Epoch 00036: val_f1-score did not improve from 0.96759\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 138s 484ms/step - loss: 0.0782 - f1-score: 0.9602 - val_loss: 0.0685 - val_f1-score: 0.9677\n",
      "\n",
      "Epoch 00037: val_f1-score improved from 0.96759 to 0.96771, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 138s 482ms/step - loss: 0.0741 - f1-score: 0.9626 - val_loss: 0.0711 - val_f1-score: 0.9668\n",
      "\n",
      "Epoch 00038: val_f1-score did not improve from 0.96771\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0733 - f1-score: 0.9626 - val_loss: 0.0720 - val_f1-score: 0.9678\n",
      "\n",
      "Epoch 00039: val_f1-score improved from 0.96771 to 0.96779, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0738 - f1-score: 0.9629 - val_loss: 0.0713 - val_f1-score: 0.9667\n",
      "\n",
      "Epoch 00040: val_f1-score did not improve from 0.96779\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0651 - f1-score: 0.9669 - val_loss: 0.0760 - val_f1-score: 0.9652\n",
      "\n",
      "Epoch 00041: val_f1-score did not improve from 0.96779\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0668 - f1-score: 0.9659 - val_loss: 0.0806 - val_f1-score: 0.9630\n",
      "\n",
      "Epoch 00042: val_f1-score did not improve from 0.96779\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0732 - f1-score: 0.9631 - val_loss: 0.0693 - val_f1-score: 0.9690\n",
      "\n",
      "Epoch 00043: val_f1-score improved from 0.96779 to 0.96903, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 137s 479ms/step - loss: 0.0631 - f1-score: 0.9683 - val_loss: 0.0670 - val_f1-score: 0.9701\n",
      "\n",
      "Epoch 00044: val_f1-score improved from 0.96903 to 0.97009, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0582 - f1-score: 0.9702 - val_loss: 0.0674 - val_f1-score: 0.9698\n",
      "\n",
      "Epoch 00045: val_f1-score did not improve from 0.97009\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0704 - f1-score: 0.9646 - val_loss: 0.0694 - val_f1-score: 0.9684\n",
      "\n",
      "Epoch 00046: val_f1-score did not improve from 0.97009\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0632 - f1-score: 0.9685 - val_loss: 0.0673 - val_f1-score: 0.9708\n",
      "\n",
      "Epoch 00047: val_f1-score improved from 0.97009 to 0.97082, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0572 - f1-score: 0.9714 - val_loss: 0.0685 - val_f1-score: 0.9714\n",
      "\n",
      "Epoch 00048: val_f1-score improved from 0.97082 to 0.97138, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0580 - f1-score: 0.9711 - val_loss: 0.0748 - val_f1-score: 0.9692\n",
      "\n",
      "Epoch 00049: val_f1-score did not improve from 0.97138\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0594 - f1-score: 0.9701 - val_loss: 0.0732 - val_f1-score: 0.9666\n",
      "\n",
      "Epoch 00050: val_f1-score did not improve from 0.97138\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0723 - f1-score: 0.9628 - val_loss: 0.0683 - val_f1-score: 0.9703\n",
      "\n",
      "Epoch 00051: val_f1-score did not improve from 0.97138\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0511 - f1-score: 0.9744 - val_loss: 0.0866 - val_f1-score: 0.9658\n",
      "\n",
      "Epoch 00052: val_f1-score did not improve from 0.97138\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0544 - f1-score: 0.9723 - val_loss: 0.0674 - val_f1-score: 0.9720\n",
      "\n",
      "Epoch 00053: val_f1-score improved from 0.97138 to 0.97197, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0532 - f1-score: 0.9723 - val_loss: 0.0732 - val_f1-score: 0.9696\n",
      "\n",
      "Epoch 00054: val_f1-score did not improve from 0.97197\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0556 - f1-score: 0.9715 - val_loss: 0.0673 - val_f1-score: 0.9714\n",
      "\n",
      "Epoch 00055: val_f1-score did not improve from 0.97197\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0503 - f1-score: 0.9746 - val_loss: 0.0718 - val_f1-score: 0.9696\n",
      "\n",
      "Epoch 00056: val_f1-score did not improve from 0.97197\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0460 - f1-score: 0.9765 - val_loss: 0.0702 - val_f1-score: 0.9705\n",
      "\n",
      "Epoch 00057: val_f1-score did not improve from 0.97197\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0442 - f1-score: 0.9775 - val_loss: 0.0732 - val_f1-score: 0.9713\n",
      "\n",
      "Epoch 00058: val_f1-score did not improve from 0.97197\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0437 - f1-score: 0.9775 - val_loss: 0.0723 - val_f1-score: 0.9696\n",
      "\n",
      "Epoch 00059: val_f1-score did not improve from 0.97197\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0442 - f1-score: 0.9773 - val_loss: 0.0721 - val_f1-score: 0.9719\n",
      "\n",
      "Epoch 00060: val_f1-score did not improve from 0.97197\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0422 - f1-score: 0.9782 - val_loss: 0.0768 - val_f1-score: 0.9694\n",
      "\n",
      "Epoch 00061: val_f1-score did not improve from 0.97197\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0457 - f1-score: 0.9767 - val_loss: 0.1205 - val_f1-score: 0.9555\n",
      "\n",
      "Epoch 00062: val_f1-score did not improve from 0.97197\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0573 - f1-score: 0.9705 - val_loss: 0.0703 - val_f1-score: 0.9709\n",
      "\n",
      "Epoch 00063: val_f1-score did not improve from 0.97197\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0420 - f1-score: 0.9783 - val_loss: 0.0723 - val_f1-score: 0.9717\n",
      "\n",
      "Epoch 00064: val_f1-score did not improve from 0.97197\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0371 - f1-score: 0.9810 - val_loss: 0.0839 - val_f1-score: 0.9691\n",
      "\n",
      "Epoch 00065: val_f1-score did not improve from 0.97197\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0379 - f1-score: 0.9804 - val_loss: 0.0787 - val_f1-score: 0.9717\n",
      "\n",
      "Epoch 00066: val_f1-score did not improve from 0.97197\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0381 - f1-score: 0.9803 - val_loss: 0.0814 - val_f1-score: 0.9693\n",
      "\n",
      "Epoch 00067: val_f1-score did not improve from 0.97197\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0384 - f1-score: 0.9802 - val_loss: 0.0755 - val_f1-score: 0.9721\n",
      "\n",
      "Epoch 00068: val_f1-score improved from 0.97197 to 0.97209, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0360 - f1-score: 0.9811 - val_loss: 0.0769 - val_f1-score: 0.9720\n",
      "\n",
      "Epoch 00069: val_f1-score did not improve from 0.97209\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0335 - f1-score: 0.9827 - val_loss: 0.0827 - val_f1-score: 0.9703\n",
      "\n",
      "Epoch 00070: val_f1-score did not improve from 0.97209\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0813 - f1-score: 0.9596 - val_loss: 0.0742 - val_f1-score: 0.9695\n",
      "\n",
      "Epoch 00071: val_f1-score did not improve from 0.97209\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0363 - f1-score: 0.9809 - val_loss: 0.0834 - val_f1-score: 0.9682\n",
      "\n",
      "Epoch 00072: val_f1-score did not improve from 0.97209\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0342 - f1-score: 0.9822 - val_loss: 0.0788 - val_f1-score: 0.9718\n",
      "\n",
      "Epoch 00073: val_f1-score did not improve from 0.97209\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0311 - f1-score: 0.9837 - val_loss: 0.0821 - val_f1-score: 0.9708\n",
      "\n",
      "Epoch 00074: val_f1-score did not improve from 0.97209\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0301 - f1-score: 0.9842 - val_loss: 0.0791 - val_f1-score: 0.9725\n",
      "\n",
      "Epoch 00075: val_f1-score improved from 0.97209 to 0.97248, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0304 - f1-score: 0.9842 - val_loss: 0.0795 - val_f1-score: 0.9707\n",
      "\n",
      "Epoch 00076: val_f1-score did not improve from 0.97248\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0334 - f1-score: 0.9824 - val_loss: 0.1133 - val_f1-score: 0.9590\n",
      "\n",
      "Epoch 00077: val_f1-score did not improve from 0.97248\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0538 - f1-score: 0.9722 - val_loss: 0.0791 - val_f1-score: 0.9700\n",
      "\n",
      "Epoch 00078: val_f1-score did not improve from 0.97248\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0321 - f1-score: 0.9829 - val_loss: 0.0772 - val_f1-score: 0.9723\n",
      "\n",
      "Epoch 00079: val_f1-score did not improve from 0.97248\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0292 - f1-score: 0.9846 - val_loss: 0.0801 - val_f1-score: 0.9728\n",
      "\n",
      "Epoch 00080: val_f1-score improved from 0.97248 to 0.97275, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0270 - f1-score: 0.9857 - val_loss: 0.0815 - val_f1-score: 0.9721\n",
      "\n",
      "Epoch 00081: val_f1-score did not improve from 0.97275\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0289 - f1-score: 0.9851 - val_loss: 0.0818 - val_f1-score: 0.9700\n",
      "\n",
      "Epoch 00082: val_f1-score did not improve from 0.97275\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0342 - f1-score: 0.9822 - val_loss: 0.0824 - val_f1-score: 0.9710\n",
      "\n",
      "Epoch 00083: val_f1-score did not improve from 0.97275\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0450 - f1-score: 0.9764 - val_loss: 0.0799 - val_f1-score: 0.9721\n",
      "\n",
      "Epoch 00084: val_f1-score did not improve from 0.97275\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0275 - f1-score: 0.9854 - val_loss: 0.0805 - val_f1-score: 0.9723\n",
      "\n",
      "Epoch 00085: val_f1-score did not improve from 0.97275\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0259 - f1-score: 0.9863 - val_loss: 0.0830 - val_f1-score: 0.9725\n",
      "\n",
      "Epoch 00086: val_f1-score did not improve from 0.97275\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0257 - f1-score: 0.9863 - val_loss: 0.0872 - val_f1-score: 0.9717\n",
      "\n",
      "Epoch 00087: val_f1-score did not improve from 0.97275\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0251 - f1-score: 0.9869 - val_loss: 0.0886 - val_f1-score: 0.9714\n",
      "\n",
      "Epoch 00088: val_f1-score did not improve from 0.97275\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0254 - f1-score: 0.9865 - val_loss: 0.0861 - val_f1-score: 0.9721\n",
      "\n",
      "Epoch 00089: val_f1-score did not improve from 0.97275\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0241 - f1-score: 0.9870 - val_loss: 0.0829 - val_f1-score: 0.9725\n",
      "\n",
      "Epoch 00090: val_f1-score did not improve from 0.97275\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0235 - f1-score: 0.9874 - val_loss: 0.0896 - val_f1-score: 0.9708\n",
      "\n",
      "Epoch 00091: val_f1-score did not improve from 0.97275\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0301 - f1-score: 0.9841 - val_loss: 0.0898 - val_f1-score: 0.9680\n",
      "\n",
      "Epoch 00092: val_f1-score did not improve from 0.97275\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0273 - f1-score: 0.9856 - val_loss: 0.0842 - val_f1-score: 0.9715\n",
      "\n",
      "Epoch 00093: val_f1-score did not improve from 0.97275\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0245 - f1-score: 0.9870 - val_loss: 0.0865 - val_f1-score: 0.9730\n",
      "\n",
      "Epoch 00094: val_f1-score improved from 0.97275 to 0.97303, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0225 - f1-score: 0.9879 - val_loss: 0.0872 - val_f1-score: 0.9733\n",
      "\n",
      "Epoch 00095: val_f1-score improved from 0.97303 to 0.97326, saving model to Unet_resnet50_100epoch_nDSM\\Unet_resnet50_100epoch_nDSM.h5\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0238 - f1-score: 0.9874 - val_loss: 0.0940 - val_f1-score: 0.9712\n",
      "\n",
      "Epoch 00096: val_f1-score did not improve from 0.97326\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0231 - f1-score: 0.9877 - val_loss: 0.0894 - val_f1-score: 0.9723\n",
      "\n",
      "Epoch 00097: val_f1-score did not improve from 0.97326\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0289 - f1-score: 0.9850 - val_loss: 0.0883 - val_f1-score: 0.9665\n",
      "\n",
      "Epoch 00098: val_f1-score did not improve from 0.97326\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0337 - f1-score: 0.9820 - val_loss: 0.0884 - val_f1-score: 0.9682\n",
      "\n",
      "Epoch 00099: val_f1-score did not improve from 0.97326\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 136s 476ms/step - loss: 0.0248 - f1-score: 0.9868 - val_loss: 0.0864 - val_f1-score: 0.9709\n",
      "\n",
      "Epoch 00100: val_f1-score did not improve from 0.97326\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = MODEL(BACKBONE, input_shape=(None, None, 4), encoder_weights=None, classes=1, activation='sigmoid', decoder_block_type='transpose')\n",
    "model.compile(OPTIMIZER, LOSS, METRICS)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpointer, csv_logger] #Earlystopping removed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8740732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 11s 256ms/step\n",
      "\n",
      "All figures saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imsave\n",
    "preds_val = model.predict(X_test, verbose=1)\n",
    "preds_val_threshold = (preds_val > 0.5).astype(np.uint8)\n",
    "\n",
    "i = -1\n",
    "for path, subdirs, _ in os.walk(r'new_test_data\\\\mask\\\\test'):\n",
    "    for dir in _:\n",
    "        if dir.endswith(\".tif\"):\n",
    "            i += 1\n",
    "            img_pred = np.reshape(preds_val_threshold[i]*255, (256,256))\n",
    "            imsave(f'{MODEL_NAME}\\\\Results\\\\{dir}', img_pred, check_contrast=False)\n",
    "print(\"\\nAll figures saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
